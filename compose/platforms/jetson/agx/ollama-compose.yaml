version: "3"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: fusionloom-ollama
    devices:
      - /dev/nvhost-ctrl:/dev/nvhost-ctrl
      - /dev/nvhost-ctrl-gpu:/dev/nvhost-ctrl-gpu
      - /dev/nvhost-prof-gpu:/dev/nvhost-prof-gpu
      - /dev/nvmap:/dev/nvmap
      - /dev/nvhost-gpu:/dev/nvhost-gpu
      - /dev/nvhost-as-gpu:/dev/nvhost-as-gpu
    volumes:
      - ./data/ollama:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Jetson-specific optimizations
      - OLLAMA_JETSON=1
      - CUDA_VISIBLE_DEVICES=0
      # Memory and performance optimizations for AGX (more resources than Orin)
      - OLLAMA_MAX_MEMORY=8G
      - OLLAMA_NUM_THREADS=8
    restart: unless-stopped
    labels:
      - "io.containers.autoupdate=image"
    networks:
      - fusionloom_net
    # Resource limits for AGX (higher than Orin)
    deploy:
      resources:
        limits:
          memory: 12G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  fusionloom_net:
    external: true
